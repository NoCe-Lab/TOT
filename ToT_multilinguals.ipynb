{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb44ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy, kruskal, f_oneway, spearmanr, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re # For parsing proficiency scores\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import gensim.models\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6dffe4-139a-434c-9141-6beef0bf3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "LEAPQ_FILE = 'results_LEAPQ.xlsx'\n",
    "TOT_FILE = 'results_TOT.xlsx'\n",
    "ASSOCIATION_FILE = 'results_association.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0601426e-1815-4944-8732-0797e2bbd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need a pre-trained word embedding model for French.\n",
    "# Download one (e.g., from fastText: https://fasttext.cc/docs/en/crawl-vectors.html)\n",
    "# and update the path below.\n",
    "# Example using gensim downloader (requires internet connection first time):\n",
    "#import gensim.downloader as api\n",
    "#model_path = api.load('fasttext-fr-300d-1M', return_path=True) # Example model\n",
    "# Or provide a direct path to the downloaded file:\n",
    "# Replace this path with the ACTUAL path where you saved the downloaded file\n",
    "WORD_EMBEDDING_MODEL_PATH = '/Users/borghesani/Documents/5_Students/UNIGE_master_students/Lina_Languer/cc.fr.300.bin' # or .bin\n",
    "LOAD_EMBEDDINGS = True # Set to False if you don't have a model or want to skip this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af97a4f7-a6aa-4d63-99ed-faed60542d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_proficiency(prof_str):\n",
    "    \"\"\"\n",
    "    Parses the proficiency string (e.g., \"9,7,5,3\") into a list of floats.\n",
    "    Handles potential non-numeric characters or formatting issues.\n",
    "    \"\"\"\n",
    "    if pd.isna(prof_str):\n",
    "        return []\n",
    "    # Remove any non-numeric characters except comma and decimal point\n",
    "    cleaned_str = re.sub(r'[^\\d,.]', '', str(prof_str))\n",
    "    try:\n",
    "        # Split and convert to float, filtering out empty strings\n",
    "        scores = [float(s.strip()) for s in cleaned_str.split(',') if s.strip()]\n",
    "        # Ensure scores are positive for log transformation\n",
    "        scores = [max(s, 1e-9) for s in scores] # Add small epsilon to avoid log(0)\n",
    "        return scores\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Could not parse proficiency string: {prof_str}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5484e3c-93ee-4fd7-a49f-de8114bae4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mlp(proficiency_data):\n",
    "    \"\"\"\n",
    "    Calculates the Multilingual Proficiency (MLP) score using entropy.\n",
    "    Handles empty lists, single language cases, and ensures scores are positive.\n",
    "    Args:\n",
    "        proficiency_data: A list of positive proficiency scores for each language.\n",
    "    Returns:\n",
    "        The MLP score (entropy), or 0 if calculation is not possible.\n",
    "    \"\"\"\n",
    "    if not proficiency_data or len(proficiency_data) == 0:\n",
    "        return 0.0 # No languages or invalid data\n",
    "\n",
    "    # Ensure all scores are positive floats\n",
    "    proficiency_data = [float(max(score, 1e-9)) for score in proficiency_data]\n",
    "\n",
    "    if len(proficiency_data) == 1:\n",
    "         # Entropy is 0 for a single language, regardless of proficiency level\n",
    "         # Represents minimal language diversity.\n",
    "        return 0.0\n",
    "\n",
    "    # Log-transform proficiency scores (already ensured positive)\n",
    "    log_proficiency = np.log(proficiency_data)\n",
    "\n",
    "    # Calculate the proportion of log-proficiency for each language\n",
    "    # Use absolute value to handle cases where sum might be negative if scores < 1\n",
    "    total_log_proficiency = np.sum(log_proficiency)\n",
    "\n",
    "    if abs(total_log_proficiency) < 1e-9:\n",
    "         # Avoid division by zero if all scores were 1 (log(1)=0)\n",
    "         # Assign uniform probability if all log scores are zero\n",
    "         proportions = np.ones(len(proficiency_data)) / len(proficiency_data)\n",
    "    else:\n",
    "         # Normalize log proficiencies to get proportions\n",
    "         # Note: This normalization differs from standard entropy calculation which uses raw probabilities.\n",
    "         # This specific method aims to capture proficiency *distribution*.\n",
    "         # Consider if standard entropy on raw scores (normalized) is more appropriate.\n",
    "         # proportions = np.array(proficiency_data) / np.sum(proficiency_data) # Standard approach\n",
    "         proportions = log_proficiency / total_log_proficiency # Method based on user's original idea\n",
    "\n",
    "         # Ensure proportions are non-negative and sum close to 1 (handle potential floating point issues)\n",
    "         proportions = np.maximum(proportions, 0)\n",
    "         proportions /= np.sum(proportions)\n",
    "\n",
    "    # Calculate entropy (using base e, as specified by base=None)\n",
    "    mlp_score = entropy(proportions, base=None)\n",
    "\n",
    "    return mlp_score\n",
    "\n",
    "    # Normalize MLP score by the maximum possible entropy (log N) ==== NOT SURE IF WE WANT TO DO THIS NORMALIZATION\n",
    "    # This makes the score range roughly between 0 and 1\n",
    "    #max_entropy = np.log(len(proficiency_data))\n",
    "    #if max_entropy > 0:\n",
    "        #normalized_mlp = mlp_score / max_entropy\n",
    "        #return normalized_mlp\n",
    "    #else:\n",
    "        #return 0.0 # Should only happen if len is 1, already handled, but for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ceab88-61dd-4d3a-af8e-30c0cb84e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_semantic_distance(target, associates, model):\n",
    "    \"\"\"\n",
    "    Calculates the average cosine distance between a target word and its associates\n",
    "    using the standard Gensim API. Handles words potentially not in the vocabulary.\n",
    "\n",
    "    Args:\n",
    "        target (str): The target word.\n",
    "        associates (list): A list of associated words (strings).\n",
    "        model: A loaded gensim KeyedVectors model (e.g., from load_facebook_vectors).\n",
    "\n",
    "    Returns:\n",
    "        The average cosine distance, or np.nan if calculation fails\n",
    "        (e.g., target not usable, or no valid associates found in the model).\n",
    "    \"\"\"\n",
    "    # --- Input Validation ---\n",
    "    if pd.isna(target) or not isinstance(target, str) or not associates:\n",
    "        return np.nan\n",
    "\n",
    "    # Clean associate list (remove potential NaNs or non-strings if list comes from pandas)\n",
    "    associates = [word for word in associates if isinstance(word, str) and pd.notna(word)]\n",
    "    if not associates:\n",
    "        return np.nan\n",
    "\n",
    "    # --- Check Target Word ---\n",
    "    # Use 'in' operator - the standard way to check vocabulary presence\n",
    "    # For FastText, this checks the known vocabulary learned during training.\n",
    "    # It does NOT check if an OOV vector *could* be generated.\n",
    "    if target not in model:\n",
    "        # print(f\"Warning: Target word '{target}' not in model vocabulary.\")\n",
    "        return np.nan\n",
    "\n",
    "    # --- Calculate Distances ---\n",
    "    distances = []\n",
    "    for assoc in associates:\n",
    "        # Use 'in' operator for associates too\n",
    "        if assoc in model:\n",
    "            try:\n",
    "                # Use the built-in model.similarity method.\n",
    "                # It's efficient and handles vector normalization.\n",
    "                # For FastText, this uses vectors from the known vocabulary.\n",
    "                similarity = model.similarity(target, assoc)\n",
    "\n",
    "                # Cosine distance = 1 - similarity\n",
    "                distance = 1.0 - similarity\n",
    "                distances.append(distance)\n",
    "\n",
    "            except KeyError:\n",
    "                # This is a safeguard, model.similarity might raise KeyError\n",
    "                # if a word passed the 'in' check but somehow isn't retrievable.\n",
    "                # print(f\"Warning: Could not compute similarity between '{target}' and '{assoc}'.\")\n",
    "                pass # Skip this associate\n",
    "        # else:\n",
    "            # print(f\"Warning: Associate word '{assoc}' for target '{target}' not in model vocabulary.\")\n",
    "            # Skip associate if not in model (implicit from the 'if assoc in model' check)\n",
    "\n",
    "    # --- Return Result ---\n",
    "    if not distances:\n",
    "        # This happens if the target was found, but none of its valid associates were.\n",
    "        # print(f\"Warning: Target '{target}' found, but none of its valid associates were in the model vocabulary.\")\n",
    "        return np.nan\n",
    "\n",
    "    return np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28af0d19-c4e6-46a6-9099-6d78ac9a26ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Data cleaned and prepared\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    df_leapq = pd.read_excel(LEAPQ_FILE)\n",
    "    df_tot = pd.read_excel(TOT_FILE)\n",
    "    df_association = pd.read_excel(ASSOCIATION_FILE)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please ensure the Excel files (results_LEAPQ.xlsx, results_TOT.xlsx, results_association.xlsx) are in the correct directory.\")\n",
    "    exit() # Exit if files are not found\n",
    "\n",
    "# --- Data Cleaning and Preparation ---\n",
    "# Clean column names (remove leading/trailing spaces, replace spaces with underscores)\n",
    "def clean_col_names(df):\n",
    "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "    return df\n",
    "\n",
    "df_leapq = clean_col_names(df_leapq)\n",
    "df_tot = clean_col_names(df_tot)\n",
    "df_association = clean_col_names(df_association)\n",
    "\n",
    "# Ensure Participant_ID is the same type for merging (string or int)\n",
    "df_leapq['Participant_ID'] = df_leapq['Participant_ID'].astype(str)\n",
    "df_tot['Participant_ID'] = df_tot['Participant_ID'].astype(str)\n",
    "df_association['Participant_ID'] = df_association['Participant_ID'].astype(str)\n",
    "\n",
    "print(\"Data cleaned and prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117980a6-5714-4130-b411-06962872775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demographic Summary ---\n",
      "Total Participants: 35\n",
      "Age: Mean=24.23, SD=7.00, Range=(19-46)\n",
      "Gender Distribution:\n",
      "Sex\n",
      "F    77.142857\n",
      "M    22.857143\n",
      "Number of Languages Spoken: Mean=4.31, SD=1.30\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Demographic Table ---\n",
    "print(\"\\n--- Demographic Summary ---\")\n",
    "mean_age = df_leapq['Age'].mean()\n",
    "std_age = df_leapq['Age'].std()\n",
    "min_age = df_leapq['Age'].min()\n",
    "max_age = df_leapq['Age'].max()\n",
    "gender_counts = df_leapq['Sex'].value_counts(normalize=True) * 100\n",
    "mean_languages = df_leapq['Number_of_Languages'].mean()\n",
    "std_languages = df_leapq['Number_of_Languages'].std()\n",
    "total_participants = len(df_leapq)\n",
    "\n",
    "print(f\"Total Participants: {total_participants}\")\n",
    "print(f\"Age: Mean={mean_age:.2f}, SD={std_age:.2f}, Range=({min_age}-{max_age})\")\n",
    "print(\"Gender Distribution:\")\n",
    "print(gender_counts.to_string())\n",
    "print(f\"Number of Languages Spoken: Mean={mean_languages:.2f}, SD={std_languages:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f3de82-7d58-4d8a-bebe-d4b1a02f77d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating MLP scores...\n",
      "MLP scores calculated.\n",
      "  Participant_ID  Proficiency       MLP\n",
      "0          10973     10,6,8,6  1.380548\n",
      "1          10974       10,9,7  1.096159\n",
      "2          10975  10,10,8,6,4  1.593105\n",
      "3          10979       10,8,7  1.096193\n",
      "4          10980        7,9,7  1.096931\n"
     ]
    }
   ],
   "source": [
    "# --- 3. MLP Calculation ---\n",
    "print(\"\\nCalculating MLP scores...\")\n",
    "# Assuming the proficiency scores are in a column named 'Proficiency' based on PDF structure\n",
    "# If the column name is different in your Excel file, change 'Proficiency' below.\n",
    "if 'Proficiency' in df_leapq.columns:\n",
    "    df_leapq['Proficiency_Scores'] = df_leapq['Proficiency'].apply(parse_proficiency)\n",
    "    df_leapq['MLP'] = df_leapq['Proficiency_Scores'].apply(calculate_mlp)\n",
    "    print(\"MLP scores calculated.\")\n",
    "    print(df_leapq[['Participant_ID', 'Proficiency', 'MLP']].head())\n",
    "else:\n",
    "    print(\"Warning: 'Proficiency' column not found in LEAPQ data. Skipping MLP calculation.\")\n",
    "    df_leapq['MLP'] = np.nan # Add MLP column with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6372b674-f90a-4f68-8a60-c0c911c6fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging datasets...\n",
      "Datasets merged.\n",
      "Merged DataFrame shape: (1573, 25)\n",
      "  Participant_ID Target_Word  Score  Number_of_Associate    Word_1     Word_2  \\\n",
      "0          10973   accordeon      4                    5     piano  mouvement   \n",
      "1          10973      agrafe      4                    7    outils   feuilles   \n",
      "2          10973    arbalete      3                    6  arbalète        Arc   \n",
      "3          10973     asperge      3                    7    patate     légume   \n",
      "4          10973    autruche      1                    4    Coulon     animal   \n",
      "\n",
      "     Word_3     Word_4   Word_5  Word_6  ... Word_12 Age  \\\n",
      "0  ensemble    musique  chanter     NaN  ...     NaN  20   \n",
      "1    utiles      école  travail  bureau  ...     NaN  20   \n",
      "2     tirer  précision      roi   force  ...     NaN  20   \n",
      "3    manger      santé     vert   santé  ...     NaN  20   \n",
      "4   méchant        fin      NaN     NaN  ...     NaN  20   \n",
      "\n",
      "                         All_Languages Number_of_Languages Mother_Tongue Sex  \\\n",
      "0  Népalais, hindi, Anglais, francais                    4      népalais   F   \n",
      "1  Népalais, hindi, Anglais, francais                    4      népalais   F   \n",
      "2  Népalais, hindi, Anglais, francais                    4      népalais   F   \n",
      "3  Népalais, hindi, Anglais, francais                    4      népalais   F   \n",
      "4  Népalais, hindi, Anglais, francais                    4      népalais   F   \n",
      "\n",
      "   Proficiency     Proficiency_Scores       MLP  \\\n",
      "0     10,6,8,6  [10.0, 6.0, 8.0, 6.0]  1.380548   \n",
      "1     10,6,8,6  [10.0, 6.0, 8.0, 6.0]  1.380548   \n",
      "2     10,6,8,6  [10.0, 6.0, 8.0, 6.0]  1.380548   \n",
      "3     10,6,8,6  [10.0, 6.0, 8.0, 6.0]  1.380548   \n",
      "4     10,6,8,6  [10.0, 6.0, 8.0, 6.0]  1.380548   \n",
      "\n",
      "                                          Associates  \n",
      "0     [piano, mouvement, ensemble, musique, chanter]  \n",
      "1  [outils, feuilles, utiles, école, travail, bur...  \n",
      "2      [arbalète, Arc, tirer, précision, roi, force]  \n",
      "3  [patate, légume, manger, santé, vert, santé, c...  \n",
      "4                     [Coulon, animal, méchant, fin]  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Merge Data ---\n",
    "print(\"\\nMerging datasets...\")\n",
    "# Use the Score from the association task (trial-level)\n",
    "df_merged = pd.merge(df_association, df_leapq, on='Participant_ID', how='left')\n",
    "# We might not need df_tot if df_association['Score'] is the primary variable\n",
    "# df_merged = pd.merge(df_merged, df_tot, on='Participant_ID', how='left') # Optional: if TOT summary needed\n",
    "\n",
    "# Extract associate words into a list for semantic distance calculation\n",
    "assoc_cols = [col for col in df_merged.columns if col.startswith('Word_')]\n",
    "df_merged['Associates'] = df_merged[assoc_cols].apply(lambda row: row.dropna().tolist(), axis=1)\n",
    "\n",
    "print(\"Datasets merged.\")\n",
    "print(f\"Merged DataFrame shape: {df_merged.shape}\")\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f38a6311-2158-4564-b93b-0b23620ce2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analysis 1: Number of Associates vs. ToT Score (Scores 3 & 4 Merged) ---\n",
      "Merged Score category 4 into 3.\n",
      "\n",
      "Mean Number of Associates per Score (Scores 3 & 4 merged):\n",
      "                  mean       std  count\n",
      "Score_Factor                           \n",
      "1             5.264249  1.889854    386\n",
      "2             5.050000  1.925960     60\n",
      "3             4.393079  1.872695   1127\n",
      "\n",
      "Kruskal-Wallis Test (Number of Associates vs. Merged Score): H=56.483, p=5.43e-13\n",
      "Significant difference found between groups.\n",
      "\n",
      "Using custom colors: ['skyblue', 'lightcoral', 'lightgreen']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 5. Hypothesis 1: Number of Associates vs. ToT Score (Modified) ---\n",
    "print(\"\\n--- Analysis 1: Number of Associates vs. ToT Score (Scores 3 & 4 Merged) ---\")\n",
    "\n",
    "# Check if 'Number_of_Associate' and 'Score' columns exist\n",
    "required_cols_h1 = ['Number_of_Associate', 'Score']\n",
    "if not all(col in df_merged.columns for col in required_cols_h1):\n",
    "    print(f\"Error: Required columns {required_cols_h1} not found in the merged data. Check column names.\")\n",
    "else:\n",
    "    # Create a copy to avoid modifying the original df_merged if needed elsewhere\n",
    "    df_analysis_h1 = df_merged[required_cols_h1].copy()\n",
    "\n",
    "    # Remove rows with NaN scores or associates if any\n",
    "    df_analysis_h1 = df_analysis_h1.dropna(subset=['Score', 'Number_of_Associate'])\n",
    "\n",
    "    # Convert Score to integer type first (important before comparison/replacement)\n",
    "    try:\n",
    "        df_analysis_h1['Score'] = df_analysis_h1['Score'].astype(int)\n",
    "    except ValueError:\n",
    "        print(\"Warning: Could not convert 'Score' column to integer. Check data.\")\n",
    "        # Handle error or exit if conversion is critical and cannot proceed\n",
    "        df_analysis_h1 = pd.DataFrame() # Clear dataframe to prevent further errors\n",
    "\n",
    "if not df_analysis_h1.empty: # Proceed only if data is valid\n",
    "\n",
    "    # --- MODIFICATION 1: Merge Score 4 into Score 3 ---\n",
    "    # Replace all occurrences of score 4 with 3\n",
    "    df_analysis_h1['Score'] = df_analysis_h1['Score'].replace(4, 3)\n",
    "    print(\"Merged Score category 4 into 3.\")\n",
    "\n",
    "    # Create categorical variable for plotting/stats\n",
    "    # Ensure categories are correctly ordered after merging (will now be 1, 2, 3)\n",
    "    unique_scores = sorted(df_analysis_h1['Score'].unique())\n",
    "    df_analysis_h1['Score_Factor'] = pd.Categorical(df_analysis_h1['Score'], categories=unique_scores, ordered=True)\n",
    "\n",
    "    # Descriptive Statistics\n",
    "    print(\"\\nMean Number of Associates per Score (Scores 3 & 4 merged):\")\n",
    "    # Use the modified 'Score' or 'Score_Factor' for grouping\n",
    "    mean_associates = df_analysis_h1.groupby('Score_Factor')['Number_of_Associate'].agg(['mean', 'std', 'count'])\n",
    "    print(mean_associates)\n",
    "\n",
    "    # Statistical Test (Kruskal-Wallis H test)\n",
    "    # Groups are now based on the modified scores (1, 2, 3)\n",
    "    score_groups = [df_analysis_h1['Number_of_Associate'][df_analysis_h1['Score'] == score]\n",
    "                    for score in sorted(df_analysis_h1['Score'].unique())]\n",
    "\n",
    "    # Check if all groups have data and there's more than one group before running the test\n",
    "    if all(len(group) > 0 for group in score_groups) and len(score_groups) > 1:\n",
    "        try:\n",
    "            stat, p_value = kruskal(*score_groups)\n",
    "            print(f\"\\nKruskal-Wallis Test (Number of Associates vs. Merged Score): H={stat:.3f}, p={p_value:.3g}\")\n",
    "            if p_value < 0.05:\n",
    "                print(\"Significant difference found between groups.\")\n",
    "                # Post-hoc tests (e.g., Dunn's test) would be needed to see which groups differ.\n",
    "            else:\n",
    "                print(\"No significant difference found between groups.\")\n",
    "        except ValueError as e:\n",
    "             print(f\"Could not perform Kruskal-Wallis test: {e}\") # Should be less likely now\n",
    "    else:\n",
    "        print(\"\\nCould not perform Kruskal-Wallis test: Not enough groups or some groups are empty after merging/filtering.\")\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # --- MODIFICATION 2: Manually specify colors ---\n",
    "    # Define your desired colors here - one for each remaining score category (1, 2, 3).\n",
    "    # Replace these examples with your actual color choices.\n",
    "    # You can use color names ('red', 'blue'), hex codes ('#FF5733'), RGB tuples, etc.\n",
    "    # Ensure the order matches the order of your categories (1, 2, 3).\n",
    "    custom_colors = ['#F2B373', '#F2E6FD', '#ECF0FE'] # Example colors for Score 1, Score 2, Score 3(merged)\n",
    "    custom_colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "    # Check if the number of colors matches the number of categories\n",
    "    n_categories = len(df_analysis_h1['Score_Factor'].cat.categories)\n",
    "    if len(custom_colors) == n_categories:\n",
    "        palette_to_use = custom_colors\n",
    "        print(f\"\\nUsing custom colors: {custom_colors}\")\n",
    "    else:\n",
    "         print(f\"\\nWarning: Number of custom colors ({len(custom_colors)}) does not match number of score categories ({n_categories}). Using default palette.\")\n",
    "         palette_to_use = 'colorblind' # Fallback to a default palette\n",
    "\n",
    "    sns.boxplot(data=df_analysis_h1, x='Score_Factor', y='Number_of_Associate', palette=palette_to_use)\n",
    "    plt.title('Number of Associates vs. ToT Score (Merged 3 & 4)')\n",
    "\n",
    "    # --- Update X-axis label to reflect merged categories ---\n",
    "    plt.xlabel('ToT Score (1=Correct, 2=Error, 3=SaidKnowToT/ToT)')\n",
    "    plt.ylabel('Number of Associates')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Skipping analysis due to data issues (missing columns, NaN values, or conversion error).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3373f81c-1cce-4c04-b447-aa158eacf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_EMBEDDINGS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653358fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analysis 2: Semantic Distance vs. ToT Score (Scores 3 & 4 Merged) ---\n",
      "Loading word embedding model from: /Users/borghesani/Documents/5_Students/UNIGE_master_students/Lina_Languer/cc.fr.300.bin...\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Hypothesis 2: Semantic Distance vs. ToT Score (Modified) ---\n",
    "print(\"\\n--- Analysis 2: Semantic Distance vs. ToT Score (Scores 3 & 4 Merged) ---\")\n",
    "\n",
    "if LOAD_EMBEDDINGS:\n",
    "    try:\n",
    "        # Check if the semantic distance column already exists; if not, calculate it\n",
    "        if 'Semantic_Distance' not in df_merged.columns:\n",
    "            print(f\"Loading word embedding model from: {WORD_EMBEDDING_MODEL_PATH}...\")\n",
    "            # Choose the appropriate loading method for your model:\n",
    "            # word_model = KeyedVectors.load_word2vec_format(WORD_EMBEDDING_MODEL_PATH, binary=True) # For Word2Vec .bin\n",
    "            # word_model = KeyedVectors.load_word2vec_format(WORD_EMBEDDING_MODEL_PATH, binary=False) # For Word2Vec .vec/.txt\n",
    "            word_model = gensim.models.fasttext.load_facebook_vectors(WORD_EMBEDDING_MODEL_PATH) # For FastText .bin\n",
    "            # word_model = KeyedVectors.load(WORD_EMBEDDING_MODEL_PATH) # For gensim native format\n",
    "            print(\"Word embedding model loaded successfully.\")\n",
    "\n",
    "            # Calculate semantic distance for each row\n",
    "            print(\"Calculating semantic distances...\")\n",
    "            df_merged['Semantic_Distance'] = df_merged.apply(\n",
    "                lambda row: calculate_semantic_distance(row.get('Target_Word'), row.get('Associates'), word_model),\n",
    "                axis=1\n",
    "            )\n",
    "            print(\"Semantic distances calculated.\")\n",
    "            # Optional: Display some results\n",
    "            # print(df_merged[['Participant_ID', 'Target_Word', 'Score', 'Associates', 'Semantic_Distance']].head())\n",
    "        else:\n",
    "             print(\"Semantic_Distance column already exists. Using existing data.\")\n",
    "\n",
    "        # --- Analysis Part ---\n",
    "        # Check if 'Semantic_Distance' and 'Score' columns exist and contain data\n",
    "        required_cols_h2 = ['Semantic_Distance', 'Score']\n",
    "        if not all(col in df_merged.columns for col in required_cols_h2):\n",
    "             print(f\"Error: Required columns {required_cols_h2} not found after calculation attempt.\")\n",
    "        else:\n",
    "            # Create a copy for analysis, including necessary columns\n",
    "            df_analysis_h2 = df_merged[required_cols_h2].copy()\n",
    "\n",
    "            # Drop rows with NaN scores or semantic distances\n",
    "            df_analysis_h2 = df_analysis_h2.dropna(subset=['Score', 'Semantic_Distance'])\n",
    "\n",
    "            # Convert Score to integer type\n",
    "            try:\n",
    "                df_analysis_h2['Score'] = df_analysis_h2['Score'].astype(int)\n",
    "            except ValueError:\n",
    "                print(\"Warning: Could not convert 'Score' column to integer in H2. Check data.\")\n",
    "                df_analysis_h2 = pd.DataFrame() # Clear df to prevent further errors\n",
    "\n",
    "            if not df_analysis_h2.empty: # Proceed only if data is valid\n",
    "\n",
    "                # *** MODIFICATION 1: Merge Score 4 into Score 3 ***\n",
    "                df_analysis_h2['Score'] = df_analysis_h2['Score'].replace(4, 3)\n",
    "                print(\"Merged Score category 4 into 3 for semantic distance analysis.\")\n",
    "\n",
    "                # Create categorical variable for plotting/stats\n",
    "                unique_scores_h2 = sorted(df_analysis_h2['Score'].unique())\n",
    "                df_analysis_h2['Score_Factor'] = pd.Categorical(df_analysis_h2['Score'], categories=unique_scores_h2, ordered=True)\n",
    "\n",
    "                # Descriptive Statistics\n",
    "                print(\"\\nMean Semantic Distance per Score (Scores 3 & 4 merged):\")\n",
    "                mean_distance = df_analysis_h2.groupby('Score_Factor')['Semantic_Distance'].agg(['mean', 'std', 'count'])\n",
    "                print(mean_distance)\n",
    "\n",
    "                # Statistical Test (Kruskal-Wallis)\n",
    "                score_groups_dist = [df_analysis_h2['Semantic_Distance'][df_analysis_h2['Score'] == score]\n",
    "                                     for score in sorted(df_analysis_h2['Score'].unique())]\n",
    "\n",
    "                # Check if all groups have data and there's more than one group\n",
    "                if all(len(group) > 0 for group in score_groups_dist) and len(score_groups_dist) > 1:\n",
    "                    try:\n",
    "                        stat_dist, p_value_dist = kruskal(*score_groups_dist)\n",
    "                        print(f\"\\nKruskal-Wallis Test (Semantic Distance vs. Merged Score): H={stat_dist:.3f}, p={p_value_dist:.3g}\")\n",
    "                        if p_value_dist < 0.05:\n",
    "                            print(\"Significant difference found between groups.\")\n",
    "                        else:\n",
    "                            print(\"No significant difference found between groups.\")\n",
    "                    except ValueError as e:\n",
    "                         print(f\"Could not perform Kruskal-Wallis test: {e}\")\n",
    "                else:\n",
    "                    print(\"\\nCould not perform Kruskal-Wallis test: Not enough groups or some groups are empty after merging/filtering.\")\n",
    "\n",
    "\n",
    "                # Plotting\n",
    "                plt.figure(figsize=(8, 6))\n",
    "\n",
    "                # *** MODIFICATION 2: Manually specify colors ***\n",
    "                # Use the same colors as Analysis 1 for consistency, or define new ones.\n",
    "                # Ensure the order matches categories (1, 2, 3).\n",
    "                custom_colors = ['skyblue', 'lightcoral', 'lightgreen'] # Example - REPLACE with your colors\n",
    "\n",
    "                # Check if the number of colors matches the number of categories\n",
    "                n_categories_h2 = len(df_analysis_h2['Score_Factor'].cat.categories)\n",
    "                if len(custom_colors) == n_categories_h2:\n",
    "                    palette_to_use = custom_colors\n",
    "                    print(f\"\\nUsing custom colors: {custom_colors}\")\n",
    "                else:\n",
    "                    print(f\"\\nWarning: Number of custom colors ({len(custom_colors)}) does not match number of score categories ({n_categories_h2}). Using fallback palette 'viridis'.\")\n",
    "                    palette_to_use = 'viridis' # Fallback palette\n",
    "\n",
    "                sns.boxplot(data=df_analysis_h2, x='Score_Factor', y='Semantic_Distance', palette=palette_to_use)\n",
    "\n",
    "                # *** Update Title and X-axis label ***\n",
    "                plt.title('Average Semantic Distance vs. ToT Score (Merged 3 & 4)')\n",
    "                plt.xlabel('ToT Score (1=Correct, 2=Error, 3=SaidKnowToT/ToT)')\n",
    "                plt.ylabel('Average Cosine Distance (Target vs. Associates)') # Or other distance metric used\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                 print(\"Skipping semantic distance analysis plotting/stats due to data issues (NaNs or conversion error).\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Word embedding model file not found at {WORD_EMBEDDING_MODEL_PATH}\")\n",
    "        print(\"Skipping semantic distance analysis.\")\n",
    "        LOAD_EMBEDDINGS = False # Prevent further errors if logic depends on this\n",
    "        if 'Semantic_Distance' not in df_merged.columns: df_merged['Semantic_Distance'] = np.nan # Ensure column exists\n",
    "    except ImportError as e:\n",
    "        print(f\"Error: Required library not installed (likely 'gensim'). {e}\")\n",
    "        print(\"Please install it (`pip install gensim`). Skipping semantic distance analysis.\")\n",
    "        LOAD_EMBEDDINGS = False\n",
    "        if 'Semantic_Distance' not in df_merged.columns: df_merged['Semantic_Distance'] = np.nan\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during semantic distance processing: {e}\")\n",
    "        LOAD_EMBEDDINGS = False\n",
    "        if 'Semantic_Distance' not in df_merged.columns: df_merged['Semantic_Distance'] = np.nan\n",
    "\n",
    "else: # if LOAD_EMBEDDINGS is False from the start\n",
    "    print(\"Skipping semantic distance analysis as LOAD_EMBEDDINGS is False.\")\n",
    "    # Ensure the column exists with NaNs if other parts of the code might expect it\n",
    "    if 'Semantic_Distance' not in df_merged.columns:\n",
    "        df_merged['Semantic_Distance'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259516c-9c17-4608-8a44-f276d61a4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Basic Data Cleaning (Example - adapt as needed) ---\n",
    "# Added MLP_Score to required columns\n",
    "required_cols = ['Participant_ID', 'Score', 'Number_of_Associate', 'Semantic_Distance', 'Number_of_Languages', 'MLP']\n",
    "if not all(col in df_merged.columns for col in required_cols):\n",
    "    missing = [col for col in required_cols if col not in df_merged.columns]\n",
    "    print(f\"Error: Missing one or more required columns: {missing}. Please check your DataFrame.\")\n",
    "    # Exit or handle error appropriately\n",
    "    exit() # Or raise an error\n",
    "\n",
    "# Convert relevant columns to numeric, handling potential errors\n",
    "for col in ['Score', 'Number_of_Associate', 'Semantic_Distance', 'Number_of_Languages', 'MLP']:\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "# Drop rows where essential numeric data is missing after conversion\n",
    "df_merged = df_merged.dropna(subset=required_cols)\n",
    "\n",
    "# --- Merge score 4 into 3 globally for consistency ---\n",
    "# Do this early so all analyses use the same merged score definition\n",
    "df_merged['Score_Merged'] = df_merged['Score'].replace(4, 3)\n",
    "print(\"Globally merged Score category 4 (Don't Know) into 3 (ToT) as 'Score_Merged'. Original 'Score' column retained if needed.\")\n",
    "\n",
    "print(\"--- Data Loaded and Basic Preparation Done ---\")\n",
    "\n",
    "# --- 1. Hypothesis 1: ToT Frequency vs. Multilingualism (Num Languages & MLP Score) ---\n",
    "# H1 (original): ToT frequency increases with the number of languages spoken.\n",
    "# Added check: Relationship between ToT freq and MLP Score, and between Num Lang and MLP Score.\n",
    "print(\"\\n--- Analysis for Hypothesis 1: ToT Frequency vs. Multilingualism Measures ---\")\n",
    "\n",
    "# Define which original score represents a ToT state\n",
    "tot_score_value = 3 # Assuming Score=3 is ToT in the *original* score column\n",
    "\n",
    "# Calculate total number of relevant trials per participant\n",
    "trials_per_participant = df_merged.groupby('Participant_ID').size()\n",
    "\n",
    "# Calculate number of ToT trials per participant using the *original* score\n",
    "tot_trials_per_participant = df_merged[df_merged['Score'] == tot_score_value].groupby('Participant_ID').size()\n",
    "\n",
    "# Get participant-level Num_Languages and MLP_Score (assuming one value per participant)\n",
    "participant_info = df_merged[['Participant_ID', 'Number_of_Languages', 'MLP']].drop_duplicates().set_index('Participant_ID')\n",
    "\n",
    "# Combine into a participant-level DataFrame\n",
    "df_participant = pd.DataFrame({\n",
    "    'Total_Trials': trials_per_participant,\n",
    "    'ToT_Trials': tot_trials_per_participant\n",
    "}).fillna(0) # Fill NaN for participants with 0 ToT trials\n",
    "\n",
    "# Calculate ToT Frequency (proportion)\n",
    "df_participant['ToT_Frequency'] = df_participant['ToT_Trials'] / df_participant['Total_Trials']\n",
    "\n",
    "# Merge with participant-level language/MLP data\n",
    "df_participant = df_participant.join(participant_info)\n",
    "\n",
    "# Remove any participants missing key data after merge\n",
    "df_participant = df_participant.dropna(subset=['Number_of_Languages', 'MLP', 'ToT_Frequency'])\n",
    "\n",
    "if not df_participant.empty and len(df_participant) > 1:\n",
    "    # Descriptive Statistics\n",
    "    print(\"\\nDescriptive Statistics for H1 (Participant Level):\")\n",
    "    print(df_participant[['Number_of_Languages', 'MLP', 'ToT_Frequency']].agg(['mean', 'std', 'min', 'max', 'count']))\n",
    "\n",
    "    # --- Statistical Tests (Correlations) ---\n",
    "    print(\"\\n--- H1 Correlations ---\")\n",
    "    # 1a: ToT Frequency vs. Number of Languages (Original H1)\n",
    "    corr_spearman_tot_numlang, p_spearman_tot_numlang = spearmanr(df_participant['Number_of_Languages'], df_participant['ToT_Frequency'])\n",
    "    print(f\"Spearman Corr (ToT Freq vs. Num Languages): rho={corr_spearman_tot_numlang:.3f}, p={p_spearman_tot_numlang:.3g}\")\n",
    "\n",
    "    # 1b: ToT Frequency vs. MLP Score\n",
    "    corr_spearman_tot_mlp, p_spearman_tot_mlp = spearmanr(df_participant['MLP'], df_participant['ToT_Frequency'])\n",
    "    print(f\"Spearman Corr (ToT Freq vs. MLP Score):       rho={corr_spearman_tot_mlp:.3f}, p={p_spearman_tot_mlp:.3g}\")\n",
    "\n",
    "    # 1c: Number of Languages vs. MLP Score (Understanding the relationship between predictors)\n",
    "    corr_spearman_numlang_mlp, p_spearman_numlang_mlp = spearmanr(df_participant['Number_of_Languages'], df_participant['MLP'])\n",
    "    print(f\"Spearman Corr (Num Languages vs. MLP Score): rho={corr_spearman_numlang_mlp:.3f}, p={p_spearman_numlang_mlp:.3g}\")\n",
    "\n",
    "    # --- Plotting H1 ---\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Plot 1a: ToT Freq vs Num Languages\n",
    "    sns.scatterplot(data=df_participant, x='Number_of_Languages', y='ToT_Frequency', ax=axes[0])\n",
    "    sns.regplot(data=df_participant, x='Number_of_Languages', y='ToT_Frequency', scatter=False, ci=95, color='red', ax=axes[0])\n",
    "    axes[0].set_title('ToT Freq vs. Num Languages')\n",
    "    axes[0].set_xlabel('Number of Languages Spoken')\n",
    "    axes[0].set_ylabel('ToT Frequency')\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Plot 1b: ToT Freq vs MLP Score\n",
    "    sns.scatterplot(data=df_participant, x='MLP', y='ToT_Frequency', ax=axes[1])\n",
    "    sns.regplot(data=df_participant, x='MLP', y='ToT_Frequency', scatter=False, ci=95, color='blue', ax=axes[1])\n",
    "    axes[1].set_title('ToT Freq vs. MLP Score')\n",
    "    axes[1].set_xlabel('MLP Score (Verify Name/Meaning)')\n",
    "    axes[1].set_ylabel('ToT Frequency')\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Plot 1c: Num Languages vs MLP Score\n",
    "    sns.scatterplot(data=df_participant, x='Number_of_Languages', y='MLP', ax=axes[2])\n",
    "    sns.regplot(data=df_participant, x='Number_of_Languages', y='MLP', scatter=False, ci=95, color='green', ax=axes[2])\n",
    "    axes[2].set_title('Num Languages vs. MLP Score')\n",
    "    axes[2].set_xlabel('Number of Languages Spoken')\n",
    "    axes[2].set_ylabel('MLP Score')\n",
    "    axes[2].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.suptitle('Hypothesis 1: Relationships with ToT Frequency', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Could not perform H1 analysis: Insufficient participant data after processing.\")\n",
    "\n",
    "\n",
    "# --- NEW PLOT: Score Distribution vs. MLP Score ---\n",
    "print(\"\\n--- Analysis: Score Distribution vs. MLP Score ---\")\n",
    "\n",
    "# Determine if MLP Score is continuous or categorical for binning/grouping\n",
    "mlp_is_continuous = df_participant['MLP'].nunique() > 10 # Heuristic: treat as continuous if >10 unique values\n",
    "bin_mlp_score = mlp_is_continuous # Set flag to bin if continuous\n",
    "\n",
    "n_mlp_bins = 3 # How many groups to create from MLP score if continuous (e.g., Low, Medium, High)\n",
    "mlp_bin_labels = ['Low MLP', 'Medium MLP', 'High MLP'] # Labels for the bins\n",
    "\n",
    "# Prepare data: Count occurrences of each *merged* score per participant\n",
    "score_counts_per_participant = df_merged.groupby(['Participant_ID', 'Score_Merged']).size().unstack(fill_value=0)\n",
    "\n",
    "# Add participant-level MLP score to these counts\n",
    "score_counts_per_participant = score_counts_per_participant.join(df_participant[['MLP']])\n",
    "score_counts_per_participant = score_counts_per_participant.dropna(subset=['MLP']) # Ensure MLP score is present\n",
    "\n",
    "if not score_counts_per_participant.empty:\n",
    "    # --- Grouping by MLP Score ---\n",
    "    if bin_mlp_score and len(score_counts_per_participant) >= n_mlp_bins:\n",
    "        print(f\"Binning continuous MLP_Score into {n_mlp_bins} groups.\")\n",
    "        try:\n",
    "            score_counts_per_participant['MLP_Group'] = pd.qcut(score_counts_per_participant['MLP'], q=n_mlp_bins, labels=mlp_bin_labels, duplicates='drop')\n",
    "            grouping_col = 'MLP_Group'\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not bin MLP_Score automatically ({e}). Using raw scores if possible, or check data.\")\n",
    "            # Fallback if qcut fails (e.g., too few participants, skewed data)\n",
    "            if not mlp_is_continuous: # If it wasn't detected as continuous initially\n",
    "                 grouping_col = 'MLP'\n",
    "                 print(\"Treating MLP as categorical.\")\n",
    "            else: # If it was continuous but binning failed, maybe skip grouping\n",
    "                 grouping_col = None\n",
    "                 print(\"Skipping grouping by MLP for plot due to binning error.\")\n",
    "    elif not mlp_is_continuous:\n",
    "        print(\"Treating MLP as categorical.\")\n",
    "        grouping_col = 'MLP' # Use raw MLP scores if they are already categorical\n",
    "    else: # Not enough data to bin\n",
    "        print(\"Warning: Not enough data points to create MLP bins. Skipping grouping.\")\n",
    "        grouping_col = None\n",
    "\n",
    "    if grouping_col:\n",
    "        # Calculate the *mean* count of each score type within each MLP group\n",
    "        mean_counts_by_mlp = score_counts_per_participant.groupby(grouping_col)[[1, 2, 3]].mean()\n",
    "        # Rename columns for clarity in the plot legend (Score 1=Correct, 2=Error, 3=ToT/DN)\n",
    "        mean_counts_by_mlp = mean_counts_by_mlp.rename(columns={1: 'Score 1 (Correct)', 2: 'Score 2 (Error)', 3: 'Score 3 (ToT/DN)'})\n",
    "        print(\"\\nMean counts of each score type per MLP group:\")\n",
    "        print(mean_counts_by_mlp)\n",
    "\n",
    "        # --- Plotting the Grouped Bar Chart ---\n",
    "        mean_counts_by_mlp.plot(kind='bar', figsize=(10, 7), rot=0)\n",
    "        plt.title('Average Trial Outcomes by MLP Group')\n",
    "        plt.xlabel('MLP Group (Verify Name/Meaning)')\n",
    "        plt.ylabel('Average Count per Participant')\n",
    "        plt.legend(title='Outcome Score')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "         print(\"Skipping Score Distribution vs MLP plot due to lack of valid grouping.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Score Distribution vs MLP plot: No data available after preparation.\")\n",
    "\n",
    "\n",
    "# --- 2. Hypothesis 2: Number of Associates vs. ToT Score ---\n",
    "# H2: When lexical access is harder, fewer words are produced.\n",
    "print(\"\\n--- Analysis for Hypothesis 2: Number of Associates vs. ToT Score (Merged 3 & 4) ---\")\n",
    "\n",
    "# Use the globally merged score column 'Score_Merged'\n",
    "df_analysis_h2 = df_merged[['Score_Merged', 'Number_of_Associate']].copy()\n",
    "df_analysis_h2 = df_analysis_h2.dropna(subset=['Score_Merged', 'Number_of_Associate'])\n",
    "df_analysis_h2['Score_Merged'] = df_analysis_h2['Score_Merged'].astype(int)\n",
    "\n",
    "if not df_analysis_h2.empty:\n",
    "    unique_scores_h2 = sorted(df_analysis_h2['Score_Merged'].unique())\n",
    "    df_analysis_h2['Score_Factor'] = pd.Categorical(df_analysis_h2['Score_Merged'], categories=unique_scores_h2, ordered=True)\n",
    "\n",
    "    # Descriptive Statistics\n",
    "    print(\"\\nMean Number of Associates per Score (Merged 3 & 4):\")\n",
    "    mean_associates = df_analysis_h2.groupby('Score_Factor')['Number_of_Associate'].agg(['mean', 'std', 'count'])\n",
    "    print(mean_associates)\n",
    "\n",
    "    # Statistical Test (Kruskal-Wallis H test)\n",
    "    score_groups_h2 = [df_analysis_h2['Number_of_Associate'][df_analysis_h2['Score_Merged'] == score]\n",
    "                       for score in unique_scores_h2]\n",
    "\n",
    "    if all(len(group) > 0 for group in score_groups_h2) and len(score_groups_h2) > 1:\n",
    "        try:\n",
    "            stat_h2, p_value_h2 = kruskal(*score_groups_h2)\n",
    "            print(f\"\\nKruskal-Wallis Test (Number of Associates vs. Merged Score): H={stat_h2:.3f}, p={p_value_h2:.3g}\")\n",
    "            if p_value_h2 < 0.05:\n",
    "                print(\"Significant difference found between groups (H2). Consider post-hoc tests.\")\n",
    "                # Add post-hoc code here if needed, using scikit-posthocs\n",
    "            else:\n",
    "                print(\"No significant difference found between groups (H2).\")\n",
    "        except ValueError as e:\n",
    "             print(f\"Could not perform Kruskal-Wallis test for H2: {e}\")\n",
    "    else:\n",
    "        print(\"\\nCould not perform Kruskal-Wallis test for H2: Not enough groups or groups empty.\")\n",
    "\n",
    "    # Plotting H2\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    custom_colors_h2 = ['skyblue', 'lightcoral', 'lightgreen'] # Colors for Score 1, Score 2, Score 3(merged)\n",
    "    n_categories_h2 = len(df_analysis_h2['Score_Factor'].cat.categories)\n",
    "    palette_h2 = custom_colors_h2 if len(custom_colors_h2) == n_categories_h2 else 'colorblind'\n",
    "\n",
    "    sns.boxplot(data=df_analysis_h2, x='Score_Factor', y='Number_of_Associate', palette=palette_h2)\n",
    "    plt.title('Hypothesis 2: Number of Associates vs. Naming Outcome')\n",
    "    plt.xlabel('Naming Outcome (1=Correct, 2=Error, 3=ToT/Don\\'t Know)')\n",
    "    plt.ylabel('Number of Associates Produced')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping H2 analysis due to data issues.\")\n",
    "\n",
    "\n",
    "# --- 3. Hypothesis 3: Semantic Relatedness vs. ToT Score ---\n",
    "# H3: When lexical access is harder, words less related are produced.\n",
    "print(\"\\n--- Analysis for Hypothesis 3: Semantic Distance vs. ToT Score (Merged 3 & 4) ---\")\n",
    "\n",
    "# Use the globally merged score column 'Score_Merged'\n",
    "df_analysis_h3 = df_merged[['Score_Merged', 'Semantic_Distance']].copy()\n",
    "df_analysis_h3 = df_analysis_h3.dropna(subset=['Score_Merged', 'Semantic_Distance'])\n",
    "df_analysis_h3['Score_Merged'] = df_analysis_h3['Score_Merged'].astype(int)\n",
    "\n",
    "if not df_analysis_h3.empty:\n",
    "    unique_scores_h3 = sorted(df_analysis_h3['Score_Merged'].unique())\n",
    "    df_analysis_h3['Score_Factor'] = pd.Categorical(df_analysis_h3['Score_Merged'], categories=unique_scores_h3, ordered=True)\n",
    "\n",
    "    # Descriptive Statistics\n",
    "    print(\"\\nMean Semantic Distance per Score (Merged 3 & 4):\")\n",
    "    mean_distance = df_analysis_h3.groupby('Score_Factor')['Semantic_Distance'].agg(['mean', 'std', 'count'])\n",
    "    print(mean_distance) # Higher distance = Less related\n",
    "\n",
    "    # Statistical Test (Kruskal-Wallis H test)\n",
    "    score_groups_h3 = [df_analysis_h3['Semantic_Distance'][df_analysis_h3['Score_Merged'] == score]\n",
    "                       for score in unique_scores_h3]\n",
    "\n",
    "    if all(len(group) > 0 for group in score_groups_h3) and len(score_groups_h3) > 1:\n",
    "        try:\n",
    "            stat_h3, p_value_h3 = kruskal(*score_groups_h3)\n",
    "            print(f\"\\nKruskal-Wallis Test (Semantic Distance vs. Merged Score): H={stat_h3:.3f}, p={p_value_h3:.3g}\")\n",
    "            if p_value_h3 < 0.05:\n",
    "                print(\"Significant difference found between groups (H3). Consider post-hoc tests.\")\n",
    "                 # Add post-hoc code here if needed\n",
    "            else:\n",
    "                print(\"No significant difference found between groups (H3).\")\n",
    "        except ValueError as e:\n",
    "             print(f\"Could not perform Kruskal-Wallis test for H3: {e}\")\n",
    "    else:\n",
    "        print(\"\\nCould not perform Kruskal-Wallis test for H3: Not enough groups or groups empty.\")\n",
    "\n",
    "    # Plotting H3\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    custom_colors_h3 = custom_colors_h2 # Use same colors as H2\n",
    "    n_categories_h3 = len(df_analysis_h3['Score_Factor'].cat.categories)\n",
    "    palette_h3 = custom_colors_h3 if len(custom_colors_h3) == n_categories_h3 else 'colorblind'\n",
    "\n",
    "    sns.boxplot(data=df_analysis_h3, x='Score_Factor', y='Semantic_Distance', palette=palette_h3)\n",
    "    plt.title('Hypothesis 3: Semantic Distance of Associates vs. Naming Outcome')\n",
    "    plt.xlabel('Naming Outcome (1=Correct, 2=Error, 3=ToT/Don\\'t Know)')\n",
    "    plt.ylabel('Mean Semantic Distance (Higher = Less Related)')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Skipping H3 analysis due to data issues.\")\n",
    "\n",
    "print(\"\\n--- All Analyses Attempted ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3342bfe-8b5d-4b6e-8554-0090a7812f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
